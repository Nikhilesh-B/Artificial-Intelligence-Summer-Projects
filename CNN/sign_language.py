# -*- coding: utf-8 -*-
"""sign_language.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NbkcBYI6xWZ8dDdZfJPoC96tRxyfVkfH

NB2953

# MNIST Sign Language
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.metrics         import accuracy_score
from sklearn.model_selection import train_test_split


import keras
from keras.utils  import to_categorical
from keras.models import Sequential
from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout

class SignLanguage:
    def __init__(self):
        self.model = None
        
        self.data = {
            "train": None, 
            "test" : None
        }
        self.create_model()
        
    
    def create_model(self):
        """
        Create a CNN model and save it to self.model
        Here we're going to have to outline the specifics of our model such that we have convolutional layers, pooling layers and a softmax activation for our final function 
        """
        
        # TODO: Create a Sequential model
        model = Sequential() 

        model.add(Conv2D(32, (3,3), activation = 'relu', input_shape = (28,28,1)))
        model.add(MaxPooling2D((2,2)))
        model.add(Conv2D(64, (3, 3), activation='relu'))
        model.add(MaxPooling2D((2, 2)))
        model.add(Dense(1000, activation='relu'))
        model.add(Dense(24, activation='softmax'))

        # TODO: Compile the model with categorical_crossentropy
        model.compile('adam', loss='categorical_crossentropy', metrics=['accuracy'])
        
        self.model = model

    




    def prepare_data(self, images, labels):
        """
        Use this method to normalize the dataset and split it into train/test.
        Save your data in self.data["train"] and self.data["test"] as a tuple
        of (images, labels)
        
        :param images numpy array of size (num_examples, 28*28)
        :param labels numpy array of size (num_examples, )
        """
        # TODO : split into training and validation set
        # TODO : reshape each example into a 2D image (28, 28, 1)
        
        ##we're splitting this data into training and testing sets that we can then accordingly implement as needed 

        ##Next steps looking through these values, ok so we're now making that split between the values of train and validation
        
        size = len(images)  ##dictactes the size of the matrix 

        division_line = int(0.9*len(images))

        training_images = images[:division_line]
        training_images = (1/255)*np.array(training_images)


        ##now reshaping these matrixes to 28*28 matrixes 
        final_training_images = []

        for vector in training_images: 
          arr = np.array(vector)
          newarr = arr.reshape(28,28,1)
          final_training_images.append(newarr)

      

        training_labels = labels[:division_line]
        final_training_labels  = to_categorical(training_labels)  

    

        test_images = images[division_line:]
        test_images =  (1/255)*np.array(test_images)

        final_test_images = [] 

        for vector in test_images: 
          arr =  np.array(vector)
          newarr = arr.reshape(28,28,1)
          final_test_images.append(newarr)
          

        test_labels = labels[division_line:]
        final_test_labels = to_categorical(test_labels)

        self.data = {
            "train":  (final_training_images, final_training_labels), #(x_train, y_train)
            "test" : (final_test_images, final_test_labels), #(x_test, y_test)
        }



    def train(self, batch_size:int=128, epochs:int=50, verbose:int=1):
        """
        Use model.fit() to train your model. Make sure to return the history for a neat visualization.
        
        :param batch_size The batch size to use for training
        :param epochs     Number of epochs to use for training
        :param verbose    Whether or not to print training output. 

        """        
       #print(len(self.data["train"][0]),len(self.data["train"][1]))
        history =  self.model.fit(self.data["train"][0],self.data["train"][1], batch_size=128,  epochs=500)

        return history

    
    def predict(self, data):
        """
        Use the trained model to predict labels for test data.
        
        :param data: numpy array of test images
        :return a numpy array of test labels. array size = (num_examples, )
        """
        
        # Don't forget to normalize the data in the same way as training data
        # self.model.predict() and np.argmax( , axis=1) might help
        

        ##normalizing the data 
        data  =  (1/255)*np.array(data)

        final_data = []
        for vector in data: 
          arr = np.array(vector)
          newarr = arr.reshape(28,28,1)
          final_data.append(newarr)

        ##so no we've normalized the data 

        prediction = self.model.predict(final_data)
        value = np.argmax(prediction)

        return value          #np.zeros(data.shape[0])
    


    def visualize_data(self, data):
        """
        Visualizing the hand gestures
        
        :param data: numpy array of images
        """
        if data is None: return
        
        nrows, ncols = 5, 5
        fig, axs = plt.subplots(nrows, ncols, figsize=(10, 10), sharex=True, sharey=True)
        plt.subplots_adjust(wspace=0, hspace=0)

        for i in range(nrows):
            for j in range(ncols):
                axs[i][j].imshow(data[0][i*ncols+j].reshape(28, 28), cmap='gray')
        plt.show()

    def visualize_accuracy(self, history):
        """
        Plots out the accuracy measures given a keras history object
        
        :param history: return value from model.fit()
        """
        if history is None: return
        
        plt.plot(history.history['acc'])
        plt.plot(history.history['val_acc'])
        plt.title("Accuracy")
        plt.xlabel('epoch')
        plt.ylabel('accuracy')
        plt.legend(['train','test'])
        plt.show()

"""# Grading Script

Do NOT modify this section
"""

if __name__=="__main__":
    train = pd.read_csv('train.csv')

    test  = pd.read_csv('test.csv')
    
    train_labels, test_labels = train['label'].values, test['label'].values
    train.drop('label', axis=1, inplace=True)
    test.drop('label', axis=1, inplace=True)
    num_classes = test_labels.max() + 1
    train_images, test_images = train.values, test.values
    print(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)

if __name__=="__main__":
    my_model = SignLanguage()
    my_model.prepare_data(train_images, train_labels)

if __name__=="__main__":
    my_model.visualize_data(my_model.data["train"])

if __name__=="__main__":
    history = my_model.train(epochs=30, verbose=1)
    my_model.visualize_accuracy(history)

if __name__=="__main__":
    y_pred = my_model.predict(test_images)
    accuracy = accuracy_score(test_labels, y_pred)
    print(accuracy)
